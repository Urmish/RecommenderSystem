% \documentclass{article}
% \usepackage{amsmath}
% \usepackage{algorithm}
% \usepackage[noend]{algpseudocode}
% \usepackage[colorlinks]{hyperref}
% 
% 
% \begin{document}
%  \pagenumbering{arabic}
\section{Model Based Systems}
  The systems based on methods discussed earlier in the lab have been widely used and produce good results. But such algorithms have been shown to have several limitations. 
  \begin{itemize}
    \item \underline{Sparsity} - Nearest Neighbor (NN) Algorithms need exact matches. As a result algorithms sacrifice recommender system coverage and accuracy [TODO FIXME ref1]. To be more precise, correlation coefficient is only defined between customers who have few products (movies in our database) in common. In an ecommerce environment where there are large number of items, one may find many customers who do not have any correlation with other customers [TODO FIXME ref2]. As a result Nearest Neighbor based algorithms are not able to recommend anything to these customers. This problem is known as the reduced coverage problem. The sparsity could also a recommender system from detecting certain obvious neighbors. 

\textit{For example - John and Susan are highly correlated, while Susan and Jack are highly correlated. Conventional wisdom might suggest John and Jack should also have similar choices, however if John and Jack have very few ratings in common, such patterns could be easily missed}
    \item \underline{Synonym Problem} - In real life scenarios, different product names can refer to similar items. Correlation based recommender systems cannot find such latent association and thus end up treating these objects as two seperate entities. 

\textit{For example, let us consider two customers one of whom rates 10 different writing pad products as "high" and another customer rates 10 different notepads as "high". NN based recommender system will not capture their association.}
  \end{itemize}
  One of the methods used to handle both the problems is the low rank approximation method. Let us do an exercise to understand the issues discussed above and see how low rank approximation can help us. \\
  \begin{table}[]
  \centering
  \label{my-label}
  \begin{tabular}{|l|l|l|l|l|}
  \hline
      & Die Hard 1 & Die Hard 2 & Die Hard 3 & Die Hard 4 \\ \hline
John  & 4          & 4          &            &            \\ \hline
Susan & 4          & 2          & 3          & 3          \\ \hline
Jack  &            &            & 4          & 4          \\ \hline
  \end{tabular}
  \caption{Truncate to Die Hard}
  \label{Model-1}
  \end{table}
\\
\begin{myremark}{\stepcounter{ques}Exercise \arabic{ques}}
Take a look at Table~\ref{Model-1}. This illustrates the example we described while discussing "Sparsity". So how do you ensure that John and Eric are considered similar to each other? Look at the code writted in "Examples/ToyExampleModelSVDMotivation.m" and see how low rank approximation helps us magically establish this relationship between John and Eric. We will discuss what this low rank approximation is and how do we calculate it in the next section. 
\end{myremark}
\\
\\
\begin{myremark}{\stepcounter{ques}Exercise \arabic{ques}}
Look at "Examples/ToyExampleModelSVDMotivation2.m". It explains a scenario similar to the talked about in Synonym Problem and looks at a potential solution 
\end{myremark}
  \subsection{Singular Vector Decomposition}

The Singular Value Decomposition (SVD) is a well known matrix factorization method. Formally, the SVD of an $m \times n$ matrix $A$ is a factorization of the form $A = U \Sigma V^{T}$ where $U$ is an $m \times m$ orthogonal matrix, $\Sigma$ is an $m \times n$ diagonal matrix with non-negative terms on the diagonal, and $V$ is an $n \times n$ orthogonal matrix. The diagonal entries of $\Sigma$ are known as the singular values of $A$. The $m$ columns of $U$ and the $n$ column of $V$ are known as the left and right singular vectors of $A$ respectively. 

The SVD gives the `best' low-rank approximation of a matrix. To put this in a more formal notation, it minimizes the Frobenius form of the difference between the approximation and the original matrix (i.e. the sum of squared errors).

Assume that matrix $A \in R^{m \times n}$ with rank $r > k$. The Frobenius norm approximation problem $min || A - Z ||_{F}$ where $rank(Z) = k$ has the solution:
\[Z = A_{k} = U_{k} \Sigma_{k} V_{k}^{T}\]
where $U_{k}, \Sigma_{k}$ and $V_{k}$ are the matrices obtained by truncating the SVD to contain only the first k singular vectors/values.

The SVD is implemented by the function $svd$ in MATLAB. You can try the following code in matlab to get an idea:
\begin{verbatim}
A = magic(3)
[U,D,V] = svd(A)
\end{verbatim}

You should observe that the columns of the matrices $U$ and $V$ are orthonormal, i.e. orthogonal unit vectors. Also note that $\Sigma$ is a diagonal matrix with non-negative and monotonically decreasing entries along the diagonal. These are the singular values of $A$. The $i^{th}$ singular value ($\Sigma_{ii}$) represents the energy content, or variance of the columns of $A$ along the $i^{th}$ left singular vector or the rows of $A$ along the $i^{th}$ right singular vector.
  \subsection{Generating Predictions}
  We can use SVD in recommender system to capture certain latent relationship between customers and products/movies. We can use this relationship to capture the predicted likeliness of a certain product/movie by a consumer. However, how do you calculate the SVD of an incomplete matrix? In order to handle this, we will study various approximations. We will then run these methods and collect empirical evidence to validate their effectiveness.
  \subsubsection{Latent Matrix Factorization}

Recommendations can be generated by a wide range of algorithms. While user-based or item-based collaborative filtering methods are simple and intuitive, matrix factorization techniques are usually more effective because they allow us to discover the latent features underlying the interactions between users and items. Of course, matrix factorization is simply a mathematical tool for playing around with matrices, and is therefore applicable in many scenarios where one would like to find out something hidden under the data.

In this section, we will go through the basic ideas and the mathematics of matrix factorization, and then we will present a simple implementation in Python. We will proceed with the assumption that we are dealing with user ratings (e.g. an integer score from the range of 1 to 5) of items in a recommendation system.
\paragraph{Basic Idea}
Just as its name suggests, matrix factorization is to factorize a matrix, i.e. to find out two (or more) matrices such that when you multiply them you will get back the original matrix.

As mentioned above, from an application point of view, matrix factorization can be used to discover latent features underlying the interactions between two different kinds of entities. And one obvious application is to predict ratings in collaborative filtering.

In a recommendation system such as Netflix or MovieLens, there is a group of users and a set of items (movies for the above two systems). Given that each users have rated some items in the system, we would like to predict how the users would rate the items that they have not yet rated, such that we can make recommendations to the users. In this case, all the information we have about the existing ratings can be represented in a matrix. Assume now we have 5 users and 10 items, and ratings are integers ranging from 1 to 5, the matrix may look something like this:
\begin{table}[ht]
\caption{User Ratings}
\centering % used for centering table
\begin{tabular}{c c c c c}
\hline\hline %inserts double horizontal lines
& D1 & D2 & D3 & D4 \\ [0.5ex] % inserts table
%heading
\hline % inserts single horizontal line
U1 & 5 & 3 & - & 1\\ % inserting body of the table
U2 & 4 & - & - & 1\\
U3 & 1 & 1 & - & 5\\
U4 & 1 & - & - & 4\\
U5 & - & 1 & - & 4\\ [1ex] % [1ex] adds vertical space
\hline %inserts single line
\end{tabular}
\end{table}

Hence, the task of predicting the missing ratings can be considered as filling in the blanks such that the values would be consistent with the existing ratings in the matrix.
 
The intuition behind using matrix factorization to solve this problem is that there should be some latent features that determine how a user rates an item. For example, two users would give high ratings to a certain movie if they both like the actors/actresses of the movie, or if the movie is an action movie, which is a genre preferred by both users. Hence, if we can discover these latent features, we should be able to predict a rating with respect to a certain user and a certain item, because the features associated with the user should match with the features associated with the item.
\paragraph{The Mathematics of Matrix Factorization}

Having discussed the intuition behind matrix factorization, we can now go on to work on the mathematics. Firstly, we have a set U of users, and a set D of items. Let $\mathbf{R}$ of size $|U| \times |D|$ be the matrix that contains all the ratings that the users have assigned to the items. Also, we assume that we would like to discover $K$ latent features. Our task, then, is to find two matrices $\mathbf{P}$ (a $|U| \times K$ matrix) and $\mathbf{Q}$ (a $|D| \times K$ matrix) such that their product approximates $\mathbf{R}$:
  \begin{gather*}
    R \approx P \times Q^{T} = \widehat{R}
  \end{gather*}

 In this way, each row of $\mathbf{P}$ would represent the strength of the associations between a user and the features. Similarly, each row of $\mathbf{Q}$ would represent the strength of the associations between an item and the features. To get the prediction of a rating of an item $d_j$ by $u_i$, we can calculate the dot product of the two vectors corresponding to $u_i$ and $d_j$:
  \begin{gather*}
    r_{ij} = p_i^{T}q_j = \sum_{k=1}^{K}p_{ik}q_{kj}
  \end{gather*}

 Now, we have to find a way to obtain $\mathbf{P}$ and $\mathbf{Q}$. One way to approach this problem is the first intialize the two matrices with some values, calculate how `different’ their product is to $\mathbf{M}$, and then try to minimize this difference iteratively. Such a method is called gradient descent, aiming at finding a local minimum of the difference.

 Here we consider the squared error because the estimated rating can be either higher or lower than the real rating.

 To minimize the error, we have to know in which direction we have to modify the values of $p_{ik}$ and $q_{kj}$. In other words, we need to know the gradient at the current values, and therefore we differentiate the above equation with respect to these two variables separately:
	\begin{gather*}
      \frac{\partial}{\partial p_{ik}}e_{ij}^2 = -2(r_{ij} - \widehat{r_{ij}})(q_{kj}) = -2e_{ij}q_{kj} \\
      \frac{\partial}{\partial q_{ik}}e_{ij}^2 = -2(r_{ij} - \widehat{r_{ij}})(p_{ik}) = -2e_{ij}p_{ik}
  \end{gather*}

 Having obtained the gradient, we can now formulate the update rules for both $p_{ik}$ and $q_{kj}$:
\begin{gather*}
      p^`_{ik} = p_{ik} + \alpha\frac{\partial}{\partial p_{ik}}e_{ij}^2 = p_{ik} + 2\alpha e_{ij}q_{kj} \\
      q^`_{kj} = q_{kj} + \alpha\frac{\partial}{\partial q_{kj}}e_{ij}^2 = q_{kj} + 2\alpha e_{ij}p_{ik}
  \end{gather*}

 Here, $\alpha$ is a constant whose value determines the rate of approaching the minimum. Usually we will choose a small value for $\alpha$, say 0.0002. This is because if we make too large a step towards the minimum we may run into the risk of missing the minimum and end up oscillating around the minimum.

 A question might have come to your mind by now: if we find two matrices $\mathbf{P}$ and $\mathbf{Q}$ such that $\mathbf{P}$ $\times$ $\mathbf{Q}$ approximates $\mathbf{R}$, isn’t that our predictions of all the unseen ratings will all be zeros? In fact, we are not really trying to come up with $\mathbf{P}$ and $\mathbf{Q}$ such that we can reproduce $\mathbf{R}$ exactly. Instead, we will only try to minimize the errors of the observed user-item pairs. In other words, if we let T be a set of tuples, each of which is in the form of $(u_i, d_j, r_{ij})$, such that T contains all the observed user-item pairs together with the associated ratings, we are only trying to minimize every $e_{ij}$ for $(u_i, d_j, r_{ij}) \in T$. (In other words, T is our set of training data.) As for the rest of the unknowns, we will be able to determine their values once the associations between the users, items and features have been learnt.

 Using the above update rules, we can then iteratively perform the operation until the error converges to its minimum. We can check the overall error as calculated using the following equation and determine when we should stop the process.
  \begin{gather*}
    E = p_i^{T}q_j = \sum_{(u_i,d_j,r_{ij})\in T} e_{ij} = \sum_{(u_i,d_j,r_{ij})\in T} (r_{ij} - \sum_{k=1}^{K}p_{ik}q_{kj})^2
  \end{gather*}
\paragraph{Regularization}

 The above algorithm is a very basic algorithm for factorizing a matrix. There are a lot of methods to make things look more complicated. A common extension to this basic algorithm is to introduce regularization to avoid over-fitting. This is done by adding a parameter $\beta$ and modify the squared error as follows:
  \begin{gather*}
    e_{ij}^2 = (r_{ij} - \sum_{k=1}^{K}p_{ik}q_{kj})^2 + \frac{\beta}{2}\sum_{k=1}^{K}(||P||^2 + ||Q||^2)^2
  \end{gather*}

 In other words, the new parameter $\beta$ is used to control the magnitudes of the user-feature and item-feature vectors such that P and Q would give a good approximation of R without having to contain large numbers. In practice, $\beta$ is set to some values in the range of 0.02. The new update rules for this squared error can be obtained by a procedure similar to the one described above. The new update rules are as follows.
\begin{gather*}
      p^`_{ik} = p_{ik} + \alpha\frac{\partial}{\partial p_{ik}}e_{ij}^2 = p_{ik} + \alpha(2e_{ij}q_{kj} - \beta p_{ik}) \\
      q^`_{kj} = q_{kj} + \alpha\frac{\partial}{\partial q_{kj}}e_{ij}^2 = q_{kj} + \alpha(2e_{ij}p_{ik} - \beta q_{kj})
  \end{gather*}
\paragraph{Implementation in Python}
\begin{lstlisting}
import numpy

def matrix_factorization(R, P, Q, K, steps=5000, alpha=0.0002, beta=0.02):
    Q = Q.T
    for step in xrange(steps):
        for i in xrange(len(R)):
            for j in xrange(len(R[i])):
                if R[i][j] > 0:
                    eij = R[i][j] - numpy.dot(P[i,:],Q[:,j])
                    for k in xrange(K):
                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])
                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])
        eR = numpy.dot(P,Q)
        e = 0
        for i in xrange(len(R)):
            for j in xrange(len(R[i])):
                if R[i][j] > 0:
                    e = e + pow(R[i][j] - numpy.dot(P[i,:],Q[:,j]), 2)
                    for k in xrange(K):
                        e = e + (beta/2) * (pow(P[i][k],2) + pow(Q[k][j],2))
        if e < 0.001:
            break
    return P, Q.T
\end{lstlisting}

 We can try to apply it to our example mentioned above and see what we would get. Below is a code snippet in Python for running the example.
\begin{lstlisting}
R = [
     [5,3,0,1],
     [4,0,0,1],
     [1,1,0,5],
     [1,0,0,4],
     [0,1,5,4],
    ]

R = numpy.array(R)

N = len(R)
M = len(R[0])
K = 2

P = numpy.random.rand(N,K)
Q = numpy.random.rand(M,K)

nP, nQ = matrix_factorization(R, P, Q, K)
nR = numpy.dot(nP, nQ.T)
\end{lstlisting}

 And the matrix obtained from the above process would look something like this:
\begin{table}[ht]
\caption{Output of Matrix Factorization}
\centering % used for centering table
\begin{tabular}{c c c c c}
\hline\hline %inserts double horizontal lines
& D1 & D2 & D3 & D4 \\ [0.5ex] % inserts table
%heading
\hline % inserts single horizontal line
U1 & 4.97 & 2.98 & 2.18 & 0.98\\ % inserting body of the table
U2 & 3.97 & 2.40 & 1.97 & 0.99\\
U3 & 1.02 & 0.93 & 5.32 & 4.93\\
U4 & 1.00 & 0.85 & 4.59 & 3.93\\
U5 & 1.36 & 1.07 & 4.89 & 4.12\\ [1ex] % [1ex] adds vertical space
\hline %inserts single line
\end{tabular}
\end{table}

 We can see that for existing ratings we have the approximations very close to the true values, and we also get some 'predictions' of the unknown values. In this simple example, we can easily see that U1 and U2 have similar taste and they both rated D1 and D2 high, while the rest of the users preferred D3, D4 and D5. When the number of features (K in the Python code) is 2, the algorithm is able to associate the users and items to two different features, and the predictions also follow these associations. For example, we can see that the predicted rating of U4 on D3 is 4.59, because U4 and U5 both rated D4 high.

  \subsubsection{Average Value Based SVD Completion}
  Below is the description of steps used to generate predictions using Average Values for SVD Completion -
  \begin{enumerate}
    \item Let $R$ be the original sparse matrix where rows represent the user and columns represent the movies
    \item Fill the empty cells in each column with average values of the product/movies in that column.
    \item Calculate the average rating for each customer $\overline{C}$ using the non zero values
    \item Let $R_{norm} = R - \overline{C}$  
    \item Factor $R_{norm}$ using SVD and obtain $U$, $S$ and $V$
    \item Truncate $U$, $S$ and $V$ to $U_k$, $S_k$ and $V_k$.
    \item Compute the resultant matrix $Pred_{norm} = U_k*S_k*V_k$
    \item Add the average customer value calculated in Step 3 to this matrix $Pred = Pred_{norm} + \overline{C} $
  \end{enumerate}
\begin{myremark}{\stepcounter{ques}Exercise \arabic{ques}}
Implement a function for average value SVD completion. Use the matrix generated from table \ref{table:example_ratings1}. Compare the result with our implementation located in Examples/ToyExampleAverageValueSVD.m
\end{myremark}
  \subsubsection{Iterative SVD Completion}
  Another simple approach to complete a matrix and generate predictions is to use iterative SVD. 
  \begin{enumerate}
    \item Let $R$ be the original sparse matrix where rows represent the user and columns represent the movies
    \item Fill the empty cells in each row with 0. Let this new Matrix be $R_{next}$
    \item Factorize $R_{next}$ using SVD and obtain $U$, $S$ and $V$
    \item Truncate $U$, $S$ and $V$ to $U_k$, $S_k$ and $V_k$.
    \item Compute the resultant matrix $R_{next} = U_k*S_k*V_k$
    \item Use the known values in $R$ to replace values in $R_{next}$
    \item Repeat the process from Step 3 $t$ number of times.
  \end{enumerate}
\begin{myremark}{\stepcounter{ques}Exercise \arabic{ques}}
Implement a function for iterative SVD completion. Use the matrix generated from table \ref{table:example_ratings1}. Compare the result with our implementation located in Examples/ToyExampleIterativeSVD.m
\end{myremark}
  \subsection{Nearest Neighbor}
  \subsubsection{Using Predicted Matrix}
  Once we have a prediction for all the movies/products for all the users, we can use nearest neighbors to generate item recommendation for a user. One may ask what use is this method if we already have a prediction? Well, nearest neighbor method can lead to something called as "Serendipity". We will discuss the meaning of Serendipity in a later section. This method is based on the assumption - given a high accuracy of prediction, we might find better neighbors and thus better ratings.
  \subsubsection{Original Matrix in Lower Dimension}
  Another work around to find better neighbors is to look for neighbors in a lower dimension space of the original sparse matrix. The motivation here is that a lower dimension space will lead to a denser matrix and might help us find better neighbors.
  \subsubsection{Which Nearest Neighbor approximation to Use?}
  To answer this question we will resort to the golden answer to life, universe and anything non concrete - \textit{"It Depends!!!"}. For the purpose of this lab we used Nearest Neighbor approach in a lower dimension space of predicted matrix. Empirically, it worked better. In general, one tries different approaches and sees what works best for their environment and their preference of error metrics.
  \subsection{Bringing it All Together}
  Now that you have all the concepts required to understand a Model Based Recommender System, we will encourage you to experiment with it to get an idea of the different tradeoffs involved and the corresponding complexity in settling down on a method.
\begin{myremark}{\stepcounter{ques}Exercise \arabic{ques}}
Look at the code in "ModelBasedPrediction / EvaluateModelBasedSVD.m" Play around with parameters, look at the impact it has on different error rates. It is upto you to decide what factors do you care about and what according to you is the best system. We have provided you with outputs for many different parameters in the table-reference-here[TODO FIXME].
\end{myremark}
  \section{Miscellaneous Topics}
  \subsection{Content Based Recommender Systems}

 Content-based recommender systems recommend an item to a user based upon a description of the item and the profile of the user’s interests. Systems implementing a content-based recommendation approach analyze a set of documents and/or descriptions of items previously rated by a user, and build a model or profile of user interests based on the features of the objects rated by that user. The profile is a structured representation of user interests, adopted to recommend new interesting items. The recommendation process basically consists in matching up the attributes of the user profile against the attributes of a content object. The result is a relevance judgment that represents the user’s level of interest in that object. If a profile accurately reflects user preferences, it is of tremendous advantage for the effectiveness of an information access process. For instance, it could be used to filter search results by deciding whether a user is interested in a specific Web page or not and, in the negative case, preventing it from being displayed.
\subsubsection{Advantages and Drawbacks of Content-based Filtering}

 The adoption of the content-based recommendation paradigm has several advantages when compared to the collaborative one:
\begin{itemize}
\item \textbf{User Independence} - Content-based recommenders exploit solely ratings provided by the active user to build her own profile.
\end{itemize}
\begin{itemize}
\item \textbf{Transparency} - Explanations on how the recommender system works can be provided by explicitly listing content features or descriptions that caused an item to occur in the list of recommendations. 
\end{itemize}
\begin{itemize}
\item \textbf{New Item} - Content-based recommenders are capable of recommending items not yet rated by any user i.e., they do not suffer from the first-rater problem.
\end{itemize}

 Nonetheless, content-based systems have several shortcomings:
\begin{itemize}
\item \textbf{Limited Content Analysis} - Content-based techniques have a natural limit in the number and type of features that are associated with the objects they recommend. Domain knowledge is often needed, e.g., for movie recommendations the system needs to know the actors and directors, and sometimes, domain ontologies are also needed. No content-based recommendation system can provide suitable suggestions if the analyzed content does not contain enough information to discriminate items the user likes from items the user does not like.
\end{itemize}
\begin{itemize}
\item \textbf{Over-Specialization} - Content-based recommenders have no inherent method for finding something unexpected. The system suggests items whose scores are high when matched against the user profile, hence the user is going to be recommended items similar to those already rated. This drawback is also called serendipity problem to highlight the tendency of the content-based systems to produce recommendations with a limited degree of novelty.
\end{itemize}
\begin{itemize}
\item \textbf{New User} - Enough ratings have to be collected before a content-based recommender system can really understand user preferences and provide accurate recommendations. Therefore, when few ratings are available, as for a new user, the system will not be able to provide reliable recommendations.
\end{itemize}

  \subsection{Serendipity}
  Recommender Systems exist to help users discover an item that he or she would like among the large pool of items available. Most of the errors that we saw did not talk about the novelty of recommendation. For example, if I have seen Star Wars: A New Hope, Star Wars: The Empire Strikes Back and Star Wars: Revenge of the Sith, I will most likely find a lot of nearest neighbors whose collective votes leads to the recommendation for The Phantom Menace, Attack of the Clones and Revenge of the Sith. I might end up liking that movie. Now consider a scenario where I end up watching a movie of a different genre altogether, say "Lincoln" and end up liking it a lot. An item based recommendation system would have never led me to discover this movie as all the movies I have rated fall into the Action/Saga/Fantasy category. Such discoveries are called serendipitous discoveries. 

Serendipity is related to unexpectedness and involves a positive emotional response of the user about a previously unknown item. It measures how surprising the unexpected recommendations that is, serendipity is concerned with the novelty of recommendations and how far such recommendations may positively affect the user. It is generally not easy to measure and most systems consider a trade-off between various forms of accuracy and serendipity. 
% \end{document}

